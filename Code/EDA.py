# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YjFBW7itS95mI8yzmhjLOgvBe5k_g5ZW
"""

# Commented out IPython magic to ensure Python compatibility.
# --- STEP 1: Install and Import Required Libraries ---
!pip install openpyxl scipy scikit-learn pandas numpy matplotlib seaborn plotly
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.signal as signal
from sklearn.model_selection import train_test_split
import plotly.express as px

# For Jupyter/Colab notebook settings
# %matplotlib inline
sns.set(style="whitegrid")

# --- STEP 2: Upload and Load Your Excel File ---
from google.colab import files
uploaded = files.upload()
excel_file = pd.ExcelFile(next(iter(uploaded)))
print("Available Sheets:", excel_file.sheet_names)

# --- STEP 3: Data Loading and Initial Cleaning ---
def load_and_clean_data(excel_file):
    """Load and clean the raw sensor data from Excel file."""
    # Load the Data In sheet
    data_in = excel_file.parse('Data In')

    # Get the header and data rows
    data = data_in.iloc[3:, :13].copy()
    data.columns = data_in.iloc[2, :13].values
    data = data[~data['TIME'].isin(['TIME', 'Historical Data'])]  # remove unwanted rows
    data = data.dropna(how='all')  # remove empty rows
    data.reset_index(drop=True, inplace=True)

    # Function to extract numerical values from strings like "AccX:-0.13"
    def extract_value(cell):
        try:
            return float(str(cell).split(":")[1])
        except:
            return np.nan

    # Create cleaned DataFrame
    df = pd.DataFrame()
    df['Timestamp'] = pd.to_datetime(data['TIME'])

    # Map sensor columns
    col_map = {
        "CH1": "AccX", "CH2": "AccY", "CH3": "AccZ", "CH4": "GyroX",
        "CH5": "GyroY", "CH6": "GyroZ", "CH7": "AccMag", "CH8": "GyroMag",
        "CH9": "Distance", "CH10": "Pressure", "CH11": "Altitude", "CH12": "Status"
    }

    for ch, name in col_map.items():
        if name != "Status":
            df[name] = data[ch].apply(extract_value)
        else:
            df[name] = data[ch].astype(str).str.extract(r'Status:(.*)')

    return df

df_raw = load_and_clean_data(excel_file)

# --- STEP 4: Exploratory Data Analysis (EDA) ---
def perform_eda(df):
    """Perform exploratory data analysis on the sensor data."""
    df_clean = df.copy()

    # Add a 'FallDetected' column based on 'Status'
    df_clean['FallDetected'] = df_clean['Status'].str.contains('Fall', case=False, na=False).astype(int)
    df_clean['FallColor'] = df_clean['FallDetected'].map({0: 'blue', 1: 'red'})
    detected_falls = df_clean[df_clean['FallDetected'] == 1].copy()

    # Basic info
    print("\n=== Basic Dataset Info ===")
    print(df_clean.info())
    display(df_clean.describe())
    print("\nUnique Status Labels:", df_clean['Status'].unique())

    # Plot time-series for main sensors
    plt.figure(figsize=(14, 6))
    sns.lineplot(x='Timestamp', y='AccMag', data=df_clean, label='AccMag')
    sns.lineplot(x='Timestamp', y='GyroMag', data=df_clean, label='GyroMag')
    plt.scatter(detected_falls['Timestamp'], detected_falls['AccMag'], color='red', marker='o', label='Detected Fall')
    plt.title("Sensor Magnitude over Time with Detected Falls")
    plt.xlabel("Time")
    plt.ylabel("Magnitude")
    plt.legend()
    plt.show()

    # Fall detection status plot
    plt.figure(figsize=(14, 4))
    plt.plot(df_clean['Timestamp'], df_clean['FallDetected'], color='black', label='Fall Detected')
    plt.title("Fall Detection Status Over Time")
    plt.xlabel("Time")
    plt.ylabel("Fall Detected (1 = Yes, 0 = No)")
    plt.legend()
    plt.show()

    # Correlation heatmap
    plt.figure(figsize=(10, 8))
    sns.heatmap(df_clean.drop(columns=['Timestamp', 'Status', 'FallDetected', 'FallColor']).corr(),
                annot=True, cmap='coolwarm')
    plt.title("Correlation Matrix of Sensor Features")
    plt.show()

    # Status distribution
    plt.figure(figsize=(6, 4))
    sns.countplot(x='Status', data=df_clean)
    plt.title("Fall Detection Status Distribution")
    plt.xticks(rotation=45)
    plt.show()

    return df_clean

df_clean = perform_eda(df_raw)

# --- STEP 5: Advanced Data Processing and Feature Engineering ---
def feature_engineering(df):
    """Perform advanced data processing and feature engineering."""
    # 1. Data Cleaning
    # Remove duplicate timestamps
    df = df[~df['Timestamp'].duplicated(keep='first')]

    # Forward fill missing values in critical columns
    for col in ['Pressure', 'Altitude', 'Status']:
        df[col] = df[col].ffill()

    # Resample to consistent time intervals with linear interpolation
    df_processed = df.set_index('Timestamp').resample('100ms').interpolate(method='linear')
    df_processed = df_processed.reset_index()

    # 2. Magnitude Features
    # Recalculate magnitudes to ensure consistency (in case original magnitudes were pre-calculated differently)
    df_processed['AccMag'] = np.sqrt(
        df_processed['AccX']**2 +
        df_processed['AccY']**2 +
        df_processed['AccZ']**2
    )

    df_processed['GyroMag'] = np.sqrt(
        df_processed['GyroX']**2 +
        df_processed['GyroY']**2 +
        df_processed['GyroZ']**2
    )

    # 3. Jerk Features (derivative of acceleration)
    time_diff = df_processed['Timestamp'].diff().dt.total_seconds()
    df_processed['JerkX'] = df_processed['AccX'].diff() / time_diff
    df_processed['JerkY'] = df_processed['AccY'].diff() / time_diff
    df_processed['JerkZ'] = df_processed['AccZ'].diff() / time_diff
    df_processed['JerkMag'] = np.sqrt(
        df_processed['JerkX']**2 +
        df_processed['JerkY']**2 +
        df_processed['JerkZ']**2
    )

    # 4. Additional Features
    # Acceleration-Gyroscope ratio
    df_processed['AccGyroRatio'] = df_processed['AccMag'] / (df_processed['GyroMag'] + 1e-6)  # Add small value to avoid division by zero

    # Signal vector magnitude (SVM)
    df_processed['SVM'] = np.sqrt(
        df_processed['AccMag']**2 +
        df_processed['GyroMag']**2
    )

    # Moving averages and standard deviations
    window_size = 10  # 1 second window for 100ms data
    for col in ['AccMag', 'GyroMag', 'JerkMag']:
        df_processed[f'{col}_MA'] = df_processed[col].rolling(window=window_size).mean()
        df_processed[f'{col}_STD'] = df_processed[col].rolling(window=window_size).std()

    # 5. Clean up (remove rows with NA values from diff and rolling operations)
    df_processed = df_processed.dropna()

    # 6. Recalculate FallDetected after processing
    df_processed['FallDetected'] = df_processed['Status'].str.contains('Fall', case=False, na=False).astype(int)

    # 7. Move Status and FallDetected columns to the end
    cols = [col for col in df_processed.columns if col not in ['Status', 'FallDetected']] + ['Status', 'FallDetected']
    df_processed = df_processed[cols]

    return df_processed

df_processed = feature_engineering(df_clean)

# --- STEP 6: Visualize Processed Data with New Features ---
def visualize_processed_data(df):
    """Visualize the processed data with new features."""
    # Create hour of day column for visualization
    df['HourOfDay'] = df['Timestamp'].dt.hour

    # Plot distributions of new features
    new_features = ['JerkMag', 'AccGyroRatio', 'SVM', 'AccMag_MA', 'GyroMag_STD']

    plt.figure(figsize=(16, 10))
    for i, col in enumerate(new_features):
        plt.subplot(2, 3, i+1)
        sns.kdeplot(data=df, x=col, hue='FallDetected', fill=True, palette={0: "blue", 1: "red"})
        plt.title(f"{col} Distribution (Fall vs. Non-Fall)")
    plt.tight_layout()
    plt.show()

    # 3D Scatter Plot with Jerk Magnitude
    fig = px.scatter_3d(df, x='AccX', y='AccY', z='AccZ',
                        color='JerkMag', size='JerkMag',
                        hover_data=['FallDetected', 'Timestamp'],
                        title="3D Accelerometer Data Colored by Jerk Magnitude")
    fig.show()

    # Time series of Jerk Magnitude with falls highlighted
    plt.figure(figsize=(14, 6))
    plt.plot(df['Timestamp'], df['JerkMag'], label='Jerk Magnitude', alpha=0.7)
    fall_points = df[df['FallDetected'] == 1]
    plt.scatter(fall_points['Timestamp'], fall_points['JerkMag'],
                color='red', s=50, label='Fall Detected')
    plt.title("Jerk Magnitude Over Time with Detected Falls")
    plt.xlabel("Time")
    plt.ylabel("Jerk Magnitude")
    plt.legend()
    plt.show()

visualize_processed_data(df_processed)

# --- STEP 7: Save Processed Data ---
df_processed.to_excel('complete_fall_detection_data_with_features.xlsx', index=False)
print("\nProcessing complete. Final data shape:", df_processed.shape)
print("\nColumns in final processed dataset:")
print(df_processed.columns.tolist())